# TradingAgentsé¡¹ç›®LangGraphå·¥ä½œæµæ‹†è§£åˆ†æ v3-å®ä¾‹

> **ç‰ˆæœ¬**: v3.0
> **æ ¸å¿ƒç†å¿µ**: ä»¥TradingAgentsä¸ºå®ä¾‹ï¼Œå±•ç¤ºå·¥ä½œæµç¼–æ’åœ¨æ™ºèƒ½äº¤æ˜“å†³ç­–ç³»ç»Ÿä¸­çš„åº”ç”¨
> **åˆ†æç›®æ ‡**: å°†å¤æ‚çš„äº¤æ˜“å†³ç­–ç³»ç»Ÿè½¬åŒ–ä¸ºå¯è§†åŒ–ã€å¯ç¼–æ’çš„å·¥ä½œæµå›¾è°±

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°ï¼šä»äº¤æ˜“å†³ç­–åˆ°å·¥ä½œæµç¼–æ’

### ä»€ä¹ˆæ˜¯TradingAgentsï¼Ÿ

TradingAgentsæ˜¯ä¸€ä¸ªåŸºäºLangGraphçš„æ™ºèƒ½äº¤æ˜“å†³ç­–ç³»ç»Ÿï¼Œé€šè¿‡å¤šAgentåä½œæ¨¡å¼ï¼Œä»æ•°æ®æ”¶é›†ã€åˆ†æè¾©è®ºåˆ°é£é™©è¯„ä¼°ï¼Œå½¢æˆå®Œæ•´çš„äº¤æ˜“å†³ç­–æµæ°´çº¿ã€‚

```mermaid
graph TB
    subgraph "ä¼ ç»Ÿäº¤æ˜“å†³ç­–æµç¨‹"
        A1[æ•°æ®æ”¶é›†] --> A2[åˆ†æç ”ç©¶] --> A3[æŠ•èµ„å†³ç­–] --> A4[é£é™©ç®¡ç†]
    end

    subgraph "TradingAgentså·¥ä½œæµç¼–æ’æ¨¡å¼"
        B1[å¤šæºæ•°æ®é‡‡é›†èŠ‚ç‚¹] --> B2{åˆ†æå¸ˆå¹¶è¡Œå¤„ç†}
        B2 --> B3[å¸‚åœºåˆ†æå¸ˆ]
        B2 --> B4[ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ]
        B2 --> B5[æ–°é—»åˆ†æå¸ˆ]
        B2 --> B6[åŸºæœ¬é¢åˆ†æå¸ˆ]

        B3 --> B7[ç‰›å¸‚ç ”ç©¶å‘˜]
        B4 --> B7
        B5 --> B7
        B6 --> B7

        B7 --> B8{è¾©è®ºå¾ªç¯}
        B8 -->|ç»§ç»­è¾©è®º| B9[ç†Šå¸‚ç ”ç©¶å‘˜]
        B9 --> B8
        B8 -->|è¾¾æˆå…±è¯†| B10[ç ”ç©¶ç»ç†]

        B10 --> B11[äº¤æ˜“å‘˜]
        B11 --> B12{é£é™©åˆ†æå¾ªç¯}
        B12 --> B13[æ¿€è¿›åˆ†æå¸ˆ]
        B12 --> B14[ä¿å®ˆåˆ†æå¸ˆ]
        B12 --> B15[ä¸­æ€§åˆ†æå¸ˆ]

        B13 --> B12
        B14 --> B12
        B15 --> B12
        B12 -->|é£é™©è¯„ä¼°å®Œæˆ| B16[é£é™©ç»ç†]
        B16 --> B17[æœ€ç»ˆäº¤æ˜“å†³ç­–]
    end
```

### æ ¸å¿ƒåˆ›æ–°ç‚¹

| ä¼ ç»Ÿæ–¹å¼ | TradingAgentså·¥ä½œæµç¼–æ’ | ä¼˜åŠ¿ |
|----------|----------------------|------|
| ä¸²è¡Œåˆ†æ | å¹¶è¡Œå¤šæºæ•°æ®åˆ†æ | æ•ˆç‡æå‡4å€ |
| å•ä¸€è§‚ç‚¹ | å¤šAgentè¾©è®ºæœºåˆ¶ | å†³ç­–æ›´å…¨é¢ |
| é™æ€æµç¨‹ | åŠ¨æ€æ¡ä»¶åˆ†æ”¯ | é€‚åº”æ€§æ›´å¼º |
| äººå·¥åˆ¤æ–­ | è‡ªåŠ¨åŒ–è´¨é‡é—¨ç¦ | ä¸€è‡´æ€§ä¿è¯ |

---

## ğŸ—ï¸ å®Œæ•´å·¥ä½œæµæ¶æ„æ‹†è§£

### ç³»ç»Ÿçº§å·¥ä½œæµå›¾è°±

```mermaid
flowchart TB
    Start([å¼€å§‹ï¼šè‚¡ç¥¨ä»£ç  + äº¤æ˜“æ—¥æœŸ]) --> Init[åˆå§‹åŒ–çŠ¶æ€èŠ‚ç‚¹]

    Init --> ParallelAnalysis{å¹¶è¡Œåˆ†æé˜¶æ®µ}

    ParallelAnalysis --> MarketAnalyst[å¸‚åœºåˆ†æå¸ˆèŠ‚ç‚¹]
    ParallelAnalysis --> SocialAnalyst[ç¤¾äº¤åª’ä½“åˆ†æå¸ˆèŠ‚ç‚¹]
    ParallelAnalysis --> NewsAnalyst[æ–°é—»åˆ†æå¸ˆèŠ‚ç‚¹]
    ParallelAnalysis --> FundamentalsAnalyst[åŸºæœ¬é¢åˆ†æå¸ˆèŠ‚ç‚¹]

    subgraph "æ•°æ®é‡‡é›†ä¸å·¥å…·è°ƒç”¨"
        MarketAnalyst --> MarketTools[å¸‚åœºæ•°æ®å·¥å…·é›†]
        SocialAnalyst --> SocialTools[ç¤¾äº¤æ•°æ®å·¥å…·é›†]
        NewsAnalyst --> NewsTools[æ–°é—»æ•°æ®å·¥å…·é›†]
        FundamentalsAnalyst --> FundTools[åŸºæœ¬é¢æ•°æ®å·¥å…·é›†]

        MarketTools --> MarketClear[å¸‚åœºæ¶ˆæ¯æ¸…ç†]
        SocialTools --> SocialClear[ç¤¾äº¤æ¶ˆæ¯æ¸…ç†]
        NewsTools --> NewsClear[æ–°é—»æ¶ˆæ¯æ¸…ç†]
        FundTools --> FundClear[åŸºæœ¬é¢æ¶ˆæ¯æ¸…ç†]
    end

    MarketClear --> ResearchDebate{ç ”ç©¶è¾©è®ºé˜¶æ®µ}
    SocialClear --> ResearchDebate
    NewsClear --> ResearchDebate
    FundClear --> ResearchDebate

    ResearchDebate --> BullResearcher[ç‰›å¸‚ç ”ç©¶å‘˜èŠ‚ç‚¹]
    BullResearcher --> DebateDecision{è¾©è®ºå†³ç­–}
    DebateDecision -->|ç»§ç»­è¾©è®º| BearResearcher[ç†Šå¸‚ç ”ç©¶å‘˜èŠ‚ç‚¹]
    BearResearcher --> DebateDecision
    DebateDecision -->|è¾¾æˆå…±è¯†| ResearchManager[ç ”ç©¶ç»ç†èŠ‚ç‚¹]

    ResearchManager --> Trader[äº¤æ˜“å‘˜èŠ‚ç‚¹]

    Trader --> RiskAnalysis{é£é™©åˆ†æé˜¶æ®µ}
    RiskAnalysis --> RiskyAnalyst[æ¿€è¿›åˆ†æå¸ˆèŠ‚ç‚¹]
    RiskyAnalyst --> RiskDecision{é£é™©å†³ç­–}
    RiskDecision --> SafeAnalyst[ä¿å®ˆåˆ†æå¸ˆèŠ‚ç‚¹]
    SafeAnalyst --> RiskDecision
    RiskDecision --> NeutralAnalyst[ä¸­æ€§åˆ†æå¸ˆèŠ‚ç‚¹]
    NeutralAnalyst --> RiskDecision
    RiskDecision -->|åˆ†æå®Œæˆ| RiskManager[é£é™©ç»ç†èŠ‚ç‚¹]

    RiskManager --> FinalDecision[æœ€ç»ˆäº¤æ˜“å†³ç­–]
    FinalDecision --> End([ç»“æŸ])

    style Start fill:#e1f5fe
    style Init fill:#f3e5f5
    style ResearchDebate fill:#fff3e0
    style RiskAnalysis fill:#ffebee
    style FinalDecision fill:#e8f5e9
    style End fill:#e8f5e9
```

### å·¥ä½œæµæ‰§è¡Œå±‚æ¬¡ç»“æ„

```mermaid
graph TB
    subgraph "ç¬¬ä¸€å±‚ï¼šæ•°æ®é‡‡é›†ç¼–æ’å™¨"
        A1[å¸‚åœºåˆ†æå¸ˆ] --> A2[ç¤¾äº¤åˆ†æå¸ˆ]
        A2 --> A3[æ–°é—»åˆ†æå¸ˆ]
        A3 --> A4[åŸºæœ¬é¢åˆ†æå¸ˆ]
    end

    subgraph "ç¬¬äºŒå±‚ï¼šç ”ç©¶è¾©è®ºç¼–æ’å™¨"
        B1[ç‰›å¸‚ç ”ç©¶å‘˜] <--> B2[ç†Šå¸‚ç ”ç©¶å‘˜]
        B2 --> B3[ç ”ç©¶ç»ç†]
    end

    subgraph "ç¬¬ä¸‰å±‚ï¼šé£é™©è¯„ä¼°ç¼–æ’å™¨"
        C1[æ¿€è¿›åˆ†æå¸ˆ] --> C2[ä¿å®ˆåˆ†æå¸ˆ]
        C2 --> C3[ä¸­æ€§åˆ†æå¸ˆ]
        C3 --> C1
        C3 --> C4[é£é™©ç»ç†]
    end

    A4 --> B1
    B3 --> T1[äº¤æ˜“å‘˜]
    T1 --> C1
    C4 --> Final[æœ€ç»ˆå†³ç­–]
```

---

## ğŸ”§ æ ¸å¿ƒèŠ‚ç‚¹è®¾è®¡æ¨¡å¼è¯¦è§£

### 1. æ•°æ®åˆ†æèŠ‚ç‚¹æ¨¡å¼

```python
# åŸºäº market_analyst.py çš„æŠ½è±¡æ¨¡å¼
class DataAnalystNode:
    """æ•°æ®åˆ†æèŠ‚ç‚¹çš„é€šç”¨æ¨¡å¼"""

    def __init__(self, llm, toolkit, node_name, data_sources):
        self.llm = llm
        self.toolkit = toolkit
        self.node_name = node_name
        self.data_sources = data_sources

    def create_analyst_node(self):
        def analyst_node(state: AgentState) -> dict:
            # 1. æå–çŠ¶æ€ä¿¡æ¯
            company_name = state.get('company_of_interest')
            trade_date = state.get('trade_date')

            # 2. å¸‚åœºç±»å‹è¯†åˆ«ï¼ˆç»Ÿä¸€ç­–ç•¥ï¼‰
            market_info = self._identify_market_type(company_name)

            # 3. æ„å»ºæ™ºèƒ½æç¤ºè¯
            prompt = self._build_context_aware_prompt(
                company_name, market_info, state
            )

            # 4. LLMå¤„ç†ä¸å·¥å…·è°ƒç”¨
            response = self._process_with_tools(prompt, state)

            # 5. æ›´æ–°çŠ¶æ€
            return self._update_state(state, response)

        return analyst_node

    def _identify_market_type(self, ticker: str) -> dict:
        """ç»Ÿä¸€çš„å¸‚åœºç±»å‹è¯†åˆ«"""
        from tradingagents.utils.stock_utils import StockUtils
        return StockUtils.get_market_info(ticker)

    def _build_context_aware_prompt(self, company, market_info, state):
        """æ„å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æç¤ºè¯"""
        currency = market_info['currency_name']
        market_name = market_info['market_name']

        return f"""
        ä½ æ˜¯ä¸“ä¸šçš„{self.node_name}ï¼Œæ­£åœ¨åˆ†æ{market_name}è‚¡ç¥¨ {company}ã€‚

        âš ï¸ é‡è¦ï¼šæ‰€æœ‰ä»·æ ¼å’Œä¼°å€¼è¯·ä½¿ç”¨{currency}ä½œä¸ºå•ä½ã€‚

        è¯·ä½¿ç”¨ä»¥ä¸‹å·¥å…·è·å–æœ€æ–°çš„{self.node_name.lower()}æ•°æ®ï¼š
        {self._format_available_tools()}

        åˆ†æé‡ç‚¹ï¼š
        {self._get_analysis_focus()}
        """
```

### 2. è¾©è®ºåè°ƒèŠ‚ç‚¹æ¨¡å¼

```python
# åŸºäº bull_researcher.py çš„æŠ½è±¡æ¨¡å¼
class DebateCoordinatorNode:
    """è¾©è®ºåè°ƒèŠ‚ç‚¹æ¨¡å¼"""

    def __init__(self, llm, memory, stance, max_rounds=2):
        self.llm = llm
        self.memory = memory
        self.stance = stance  # "bull", "bear", "neutral"
        self.max_rounds = max_rounds

    def create_debate_node(self):
        def debate_node(state: AgentState) -> dict:
            # 1. è·å–è¾©è®ºçŠ¶æ€
            debate_state = state["investment_debate_state"]

            # 2. æ£€ç´¢ç›¸å…³è®°å¿†
            past_memories = self._retrieve_memories(state)

            # 3. æ„å»ºç«‹åœºåŒ–æç¤ºè¯
            prompt = self._build_stance_prompt(state, past_memories)

            # 4. ç”Ÿæˆè¾©è®ºå›åº”
            response = self._generate_debate_response(prompt)

            # 5. æ›´æ–°è¾©è®ºçŠ¶æ€
            return self._update_debate_state(state, response)

        return debate_node

    def _build_stance_prompt(self, state, memories):
        """æ„å»ºåŸºäºç«‹åœºçš„æç¤ºè¯"""
        stance_prompts = {
            "bull": self._bull_stance_prompt,
            "bear": self._bear_stance_prompt,
            "neutral": self._neutral_stance_prompt
        }
        return stance_prompts[self.stance](state, memories)

    def _bull_stance_prompt(self, state, memories):
        """çœ‹æ¶¨ç«‹åœºæç¤ºè¯"""
        company = state.get('company_of_interest', 'Unknown')
        market_info = self._get_market_info(company)

        return f"""
        ä½ æ˜¯çœ‹æ¶¨åˆ†æå¸ˆï¼Œä¸º{company}å»ºç«‹å¼ºæœ‰åŠ›çš„æŠ•èµ„è®ºè¯ã€‚

        å¸‚åœºèƒŒæ™¯ï¼š{market_info['market_name']}ï¼Œè´§å¸å•ä½ï¼š{market_info['currency_name']}

        æ ¸å¿ƒä»»åŠ¡ï¼š
        1. çªå‡ºå¢é•¿æ½œåŠ›å’Œç«äº‰ä¼˜åŠ¿
        2. ç”¨æ•°æ®åé©³çœ‹è·Œè§‚ç‚¹
        3. å»ºç«‹ä»¤äººä¿¡æœçš„çœ‹æ¶¨æ¡ˆä¾‹

        å¯ç”¨ä¿¡æ¯ï¼š
        - å¸‚åœºç ”ç©¶ï¼š{state.get('market_report', '')}
        - åŸºæœ¬é¢åˆ†æï¼š{state.get('fundamentals_report', '')}
        - å†å²ç»éªŒï¼š{self._format_memories(memories)}
        - å¯¹æ‰‹è§‚ç‚¹ï¼š{state['investment_debate_state'].get('current_response', '')}
        """
```

### 3. æ¡ä»¶å†³ç­–èŠ‚ç‚¹æ¨¡å¼

```python
# åŸºäº conditional_logic.py çš„æŠ½è±¡æ¨¡å¼
class ConditionalDecisionNode:
    """æ¡ä»¶å†³ç­–èŠ‚ç‚¹æ¨¡å¼"""

    def __init__(self, decision_criteria):
        self.decision_criteria = decision_criteria

    def create_decision_router(self, decision_type):
        """åˆ›å»ºå†³ç­–è·¯ç”±å™¨"""
        decision_routers = {
            "tool_continuation": self._tool_continuation_router,
            "debate_progression": self._debate_progression_router,
            "risk_analysis": self._risk_analysis_router,
            "quality_gate": self._quality_gate_router
        }
        return decision_routers[decision_type]

    def _tool_continuation_router(self, state: AgentState):
        """å·¥å…·ç»§ç»­è°ƒç”¨å†³ç­–"""
        messages = state["messages"]
        last_message = messages[-1]

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å·¥å…·è°ƒç”¨
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return f"tools_{self._get_current_analyst_type(state)}"
        return f"Msg Clear {self._get_current_analyst_type(state).capitalize()}"

    def _debate_progression_router(self, state: AgentState) -> str:
        """è¾©è®ºè¿›å±•å†³ç­–"""
        debate_state = state["investment_debate_state"]

        # æ£€æŸ¥è¾è½®æ¬¡é™åˆ¶
        if debate_state["count"] >= 2 * self.decision_criteria["max_debate_rounds"]:
            return "Research Manager"

        # å†³å®šä¸‹ä¸€ä¸ªå‘è¨€è€…
        if debate_state["current_response"].startswith("Bull"):
            return "Bear Researcher"
        return "Bull Researcher"

    def _quality_gate_router(self, state: AgentState) -> str:
        """è´¨é‡é—¨ç¦å†³ç­–"""
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        required_reports = ["market_report", "fundamentals_report", "news_report"]
        missing_reports = [r for r in required_reports if not state.get(r)]

        if missing_reports:
            return f"Retry_{missing_reports[0].split('_')[0]}_Analysis"

        # æ£€æŸ¥è¾©è®ºè´¨é‡
        debate_state = state["investment_debate_state"]
        if len(debate_state.get("history", "")) < 100:
            return "Continue_Debate"

        return "Proceed_To_Trading"
```

---

## ğŸ“¦ çŠ¶æ€ç®¡ç†æ¶æ„

### ç»Ÿä¸€çŠ¶æ€æ¨¡å‹

```python
# åŸºäº agent_states.py çš„å®Œæ•´çŠ¶æ€æ¨¡å‹
from typing import TypedDict, Annotated
from langgraph.graph import MessagesState

class TradingWorkflowState(MessagesState):
    """äº¤æ˜“å·¥ä½œæµçš„å®Œæ•´çŠ¶æ€å®šä¹‰"""

    # === åŸºç¡€ä¿¡æ¯ ===
    company_of_interest: Annotated[str, "ç›®æ ‡è‚¡ç¥¨ä»£ç "]
    trade_date: Annotated[str, "äº¤æ˜“æ—¥æœŸ"]
    sender: Annotated[str, "å½“å‰å‘é€æ¶ˆæ¯çš„Agent"]

    # === åˆ†ææŠ¥å‘Š ===
    market_report: Annotated[str, "å¸‚åœºåˆ†ææŠ¥å‘Š"]
    sentiment_report: Annotated[str, "ç¤¾äº¤åª’ä½“æƒ…ç»ªæŠ¥å‘Š"]
    news_report: Annotated[str, "æ–°é—»åˆ†ææŠ¥å‘Š"]
    fundamentals_report: Annotated[str, "åŸºæœ¬é¢åˆ†ææŠ¥å‘Š"]

    # === æŠ•èµ„è¾©è®ºçŠ¶æ€ ===
    investment_debate_state: Annotated[InvestDebateState, "æŠ•èµ„è¾©è®ºçŠ¶æ€"]
    investment_plan: Annotated[str, "æŠ•èµ„è®¡åˆ’"]
    trader_investment_plan: Annotated[str, "äº¤æ˜“å‘˜æŠ•èµ„è®¡åˆ’"]

    # === é£é™©åˆ†æçŠ¶æ€ ===
    risk_debate_state: Annotated[RiskDebateState, "é£é™©è¾©è®ºçŠ¶æ€"]
    final_trade_decision: Annotated[str, "æœ€ç»ˆäº¤æ˜“å†³ç­–"]

class InvestDebateState(TypedDict):
    """æŠ•èµ„è¾©è®ºå­çŠ¶æ€"""
    bull_history: Annotated[str, "çœ‹æ¶¨è§‚ç‚¹å†å²"]
    bear_history: Annotated[str, "çœ‹è·Œè§‚ç‚¹å†å²"]
    history: Annotated[str, "å®Œæ•´å¯¹è¯å†å²"]
    current_response: Annotated[str, "å½“å‰å›åº”"]
    judge_decision: Annotated[str, "è£åˆ¤å†³ç­–"]
    count: Annotated[int, "å¯¹è¯è½®æ¬¡è®¡æ•°"]

class RiskDebateState(TypedDict):
    """é£é™©è¾©è®ºå­çŠ¶æ€"""
    risky_history: Annotated[str, "æ¿€è¿›è§‚ç‚¹å†å²"]
    safe_history: Annotated[str, "ä¿å®ˆè§‚ç‚¹å†å²"]
    neutral_history: Annotated[str, "ä¸­æ€§è§‚ç‚¹å†å²"]
    history: Annotated[str, "å®Œæ•´å¯¹è¯å†å²"]
    latest_speaker: Annotated[str, "æœ€åå‘è¨€è€…"]
    current_risky_response: Annotated[str, "æ¿€è¿›åˆ†æå¸ˆå›åº”"]
    current_safe_response: Annotated[str, "ä¿å®ˆåˆ†æå¸ˆå›åº”"]
    current_neutral_response: Annotated[str, "ä¸­æ€§åˆ†æå¸ˆå›åº”"]
    judge_decision: Annotated[str, "é£é™©ç»ç†å†³ç­–"]
    count: Annotated[int, "å¯¹è¯è½®æ¬¡è®¡æ•°"]
```

### çŠ¶æ€ä¼ æ’­æ¨¡å¼

```python
# åŸºäº propagation.py çš„çŠ¶æ€ä¼ æ’­æœºåˆ¶
class StateHandler:
    """çŠ¶æ€å¤„ç†å™¨ï¼šç®¡ç†å·¥ä½œæµä¸­çš„çŠ¶æ€ä¼ æ’­"""

    def create_initial_state(self, company_name: str, trade_date: str) -> TradingWorkflowState:
        """åˆ›å»ºåˆå§‹çŠ¶æ€"""
        return {
            "company_of_interest": company_name,
            "trade_date": trade_date,
            "messages": [],
            "sender": "System",

            # åˆå§‹åŒ–æ‰€æœ‰æŠ¥å‘Šä¸ºç©º
            "market_report": "",
            "sentiment_report": "",
            "news_report": "",
            "fundamentals_report": "",

            # åˆå§‹åŒ–è¾©è®ºçŠ¶æ€
            "investment_debate_state": {
                "bull_history": "",
                "bear_history": "",
                "history": "",
                "current_response": "",
                "judge_decision": "",
                "count": 0
            },

            # åˆå§‹åŒ–é£é™©çŠ¶æ€
            "risk_debate_state": {
                "risky_history": "",
                "safe_history": "",
                "neutral_history": "",
                "history": "",
                "latest_speaker": "",
                "current_risky_response": "",
                "current_safe_response": "",
                "current_neutral_response": "",
                "judge_decision": "",
                "count": 0
            },

            "investment_plan": "",
            "trader_investment_plan": "",
            "final_trade_decision": ""
        }

    def update_report_state(self, state: TradingWorkflowState,
                           report_type: str, content: str) -> TradingWorkflowState:
        """æ›´æ–°æŠ¥å‘ŠçŠ¶æ€"""
        state[f"{report_type}_report"] = content
        return state

    def update_debate_state(self, state: TradingWorkflowState,
                          debate_type: str, speaker: str,
                          response: str) -> TradingWorkflowState:
        """æ›´æ–°è¾©è®ºçŠ¶æ€"""
        if debate_type == "investment":
            debate_state = state["investment_debate_state"]
            debate_state["current_response"] = f"{speaker}: {response}"
            debate_state["history"] += f"\n{speaker}: {response}"
            debate_state["count"] += 1

            if speaker.startswith("Bull"):
                debate_state["bull_history"] += f"\n{response}"
            elif speaker.startswith("Bear"):
                debate_state["bear_history"] += f"\n{response}"

        elif debate_type == "risk":
            risk_state = state["risk_debate_state"]
            risk_state["latest_speaker"] = speaker
            risk_state["history"] += f"\n{speaker}: {response}"
            risk_state["count"] += 1

            if speaker.startswith("Risky"):
                risk_state["current_risky_response"] = response
                risk_state["risky_history"] += f"\n{response}"
            elif speaker.startswith("Safe"):
                risk_state["current_safe_response"] = response
                risk_state["safe_history"] += f"\n{response}"
            elif speaker.startswith("Neutral"):
                risk_state["current_neutral_response"] = response
                risk_state["neutral_history"] += f"\n{response}"

        return state
```

---

## ğŸ® æ™ºèƒ½å†³ç­–æœºåˆ¶

### åŠ¨æ€æ¡ä»¶è·¯ç”±ç³»ç»Ÿ

```mermaid
graph TB
    subgraph "å·¥å…·è°ƒç”¨å†³ç­–"
        A1[æ£€æŸ¥æœ€åæ¶ˆæ¯] --> A2{æ˜¯å¦æœ‰tool_calls?}
        A2 -->|æœ‰| A3[è°ƒç”¨å¯¹åº”å·¥å…·èŠ‚ç‚¹]
        A2 -->|æ— | A4[æ¸…ç†æ¶ˆæ¯å¹¶ç»§ç»­]
    end

    subgraph "è¾©è®ºæµç¨‹å†³ç­–"
        B1[æ£€æŸ¥è¾©è®ºè½®æ¬¡] --> B2{è¾¾åˆ°æœ€å¤§è½®æ¬¡?}
        B2 -->|æ˜¯| B3[è¿›å…¥å†³ç­–é˜¶æ®µ]
        B2 -->|å¦| B4{æ£€æŸ¥å½“å‰å‘è¨€è€…}
        B4 -->|Bull| B5[åˆ‡æ¢åˆ°Bear]
        B4 -->|Bear| B6[åˆ‡æ¢åˆ°Bull]
    end

    subgraph "é£é™©åˆ†æå†³ç­–"
        C1[æ£€æŸ¥åˆ†æè½®æ¬¡] --> C2{è¾¾åˆ°æœ€å¤§è½®æ¬¡?}
        C2 -->|æ˜¯| C3[é£é™©ç»ç†æ€»ç»“]
        C2 -->|å¦| C4{æ£€æŸ¥æœ€åå‘è¨€è€…}
        C4 -->|Risky| C5[åˆ‡æ¢åˆ°Safe]
        C4 -->|Safe| C6[åˆ‡æ¢åˆ°Neutral]
        C4 -->|Neutral| C7[åˆ‡æ¢åˆ°Risky]
    end
```

### è®°å¿†ç³»ç»Ÿé›†æˆ

```python
# åŸºäº memory.py çš„è®°å¿†ç³»ç»Ÿ
class WorkflowMemoryManager:
    """å·¥ä½œæµè®°å¿†ç®¡ç†å™¨"""

    def __init__(self, config):
        self.memories = {
            "bull_memory": FinancialSituationMemory("bull_memory", config),
            "bear_memory": FinancialSituationMemory("bear_memory", config),
            "trader_memory": FinancialSituationMemory("trader_memory", config),
            "invest_judge_memory": FinancialSituationMemory("invest_judge_memory", config),
            "risk_manager_memory": FinancialSituationMemory("risk_manager_memory", config)
        }

    def get_contextual_memories(self, agent_type: str, current_situation: str,
                              n_matches: int = 2) -> List[dict]:
        """è·å–ä¸Šä¸‹æ–‡ç›¸å…³çš„è®°å¿†"""
        if agent_type in self.memories and self.memories[agent_type] is not None:
            return self.memories[agent_type].get_memories(current_situation, n_matches)
        return []

    def store_decision_outcome(self, agent_type: str, situation: str,
                             decision: str, outcome: float):
        """å­˜å‚¨å†³ç­–ç»“æœç”¨äºå­¦ä¹ """
        if agent_type in self.memories and self.memories[agent_type] is not None:
            self.memories[agent_type].add_memory(
                situation=situation,
                recommendation=decision,
                returns=outcome
            )
```

### è´¨é‡é—¨ç¦ä¸åé¦ˆæœºåˆ¶

```python
# åŸºäº reflection.py çš„åæ€æœºåˆ¶
class QualityGateAndReflection:
    """è´¨é‡é—¨ç¦ä¸åæ€æœºåˆ¶"""

    def __init__(self, llm):
        self.llm = llm

    def validate_analysis_quality(self, state: TradingWorkflowState) -> tuple[bool, str]:
        """éªŒè¯åˆ†æè´¨é‡"""
        quality_checks = {
            "data_completeness": self._check_data_completeness(state),
            "argument_coherence": self._check_argument_coherence(state),
            "risk_coverage": self._check_risk_coverage(state),
            "decision_logic": self._check_decision_logic(state)
        }

        failed_checks = [k for k, v in quality_checks.items() if not v]

        if failed_checks:
            return False, f"è´¨é‡æ£€æŸ¥å¤±è´¥: {', '.join(failed_checks)}"
        return True, "è´¨é‡æ£€æŸ¥é€šè¿‡"

    def reflect_and_improve(self, state: TradingWorkflowState,
                          actual_returns: float) -> dict:
        """åŸºäºå®é™…æ”¶ç›Šè¿›è¡Œåæ€å’Œæ”¹è¿›"""
        reflection_prompt = f"""
        åˆ†æä»¥ä¸‹äº¤æ˜“å†³ç­–çš„è¡¨ç°ï¼š

        åŸå§‹å†³ç­–ï¼š{state['final_trade_decision']}
        å®é™…æ”¶ç›Šï¼š{actual_returns}

        è¯·è¯„ä¼°ï¼š
        1. å†³ç­–è´¨é‡å¦‚ä½•ï¼Ÿ
        2. å“ªäº›åˆ†ææ˜¯å‡†ç¡®çš„ï¼Ÿ
        3. å“ªäº›åœ°æ–¹å¯ä»¥æ”¹è¿›ï¼Ÿ
        4. å¯¹æœªæ¥ç±»ä¼¼æƒ…å†µçš„å»ºè®®ï¼Ÿ
        """

        reflection_result = self.llm.invoke(reflection_prompt)

        return {
            "decision": state['final_trade_decision'],
            "returns": actual_returns,
            "reflection": reflection_result.content,
            "timestamp": state['trade_date']
        }
```

---

## ğŸš€ å®Œæ•´å·¥ä½œæµå®ç°ç¤ºä¾‹

### TradingAgentså·¥ä½œæµæ„å»ºå™¨

```python
# åŸºäº trading_graph.py çš„å®Œæ•´å®ç°
class TradingAgentsWorkflowBuilder:
    """äº¤æ˜“æ™ºèƒ½ä½“å·¥ä½œæµæ„å»ºå™¨"""

    def __init__(self, config: dict):
        self.config = config
        self.llm_setup = LLMSetup(config)
        self.memory_manager = WorkflowMemoryManager(config)
        self.quality_gate = QualityGateAndReflection(self.llm_setup.quick_thinking_llm)

    def create_workflow(self, selected_analysts=["market", "social", "news", "fundamentals"]):
        """åˆ›å»ºå®Œæ•´çš„äº¤æ˜“å†³ç­–å·¥ä½œæµ"""

        # 1. åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(TradingWorkflowState)

        # 2. æ·»åŠ æ•°æ®åˆ†æèŠ‚ç‚¹
        self._add_analysis_nodes(workflow, selected_analysts)

        # 3. æ·»åŠ è¾©è®ºèŠ‚ç‚¹
        self._add_debate_nodes(workflow)

        # 4. æ·»åŠ å†³ç­–èŠ‚ç‚¹
        self._add_decision_nodes(workflow)

        # 5. æ·»åŠ é£é™©ç®¡ç†èŠ‚ç‚¹
        self._add_risk_management_nodes(workflow)

        # 6. é…ç½®è¾¹å’Œæ¡ä»¶é€»è¾‘
        self._configure_edges(workflow, selected_analysts)

        # 7. ç¼–è¯‘å·¥ä½œæµ
        return workflow.compile()

    def _add_analysis_nodes(self, workflow, selected_analysts):
        """æ·»åŠ åˆ†æèŠ‚ç‚¹"""
        analyst_configs = {
            "market": {"tools": ["get_stock_market_data_unified", "get_YFin_data_online"]},
            "social": {"tools": ["get_stock_news_openai", "get_reddit_stock_info"]},
            "news": {"tools": ["get_global_news_openai", "get_google_news"]},
            "fundamentals": {"tools": ["get_stock_fundamentals_unified", "get_simfin_balance_sheet"]}
        }

        for analyst_type in selected_analysts:
            config = analyst_configs[analyst_type]

            # åˆ›å»ºåˆ†æå¸ˆèŠ‚ç‚¹
            analyst_node = DataAnalystNode(
                self.llm_setup.quick_thinking_llm,
                self.toolkit,
                f"{analyst_type}_analyst",
                config["tools"]
            ).create_analyst_node()

            # åˆ›å»ºå·¥å…·èŠ‚ç‚¹
            tool_node = ToolNode([getattr(self.toolkit, tool) for tool in config["tools"]])

            # åˆ›å»ºæ¶ˆæ¯æ¸…ç†èŠ‚ç‚¹
            clear_node = create_msg_delete()

            # æ·»åŠ åˆ°å·¥ä½œæµ
            workflow.add_node(f"{analyst_type.capitalize()} Analyst", analyst_node)
            workflow.add_node(f"tools_{analyst_type}", tool_node)
            workflow.add_node(f"Msg Clear {analyst_type.capitalize()}", clear_node)

    def _add_debate_nodes(self, workflow):
        """æ·»åŠ è¾©è®ºèŠ‚ç‚¹"""
        # ç‰›å¸‚ç ”ç©¶å‘˜
        bull_node = DebateCoordinatorNode(
            self.llm_setup.quick_thinking_llm,
            self.memory_manager.memories["bull_memory"],
            "bull"
        ).create_debate_node()

        # ç†Šå¸‚ç ”ç©¶å‘˜
        bear_node = DebateCoordinatorNode(
            self.llm_setup.quick_thinking_llm,
            self.memory_manager.memories["bear_memory"],
            "bear"
        ).create_debate_node()

        # ç ”ç©¶ç»ç†ï¼ˆå†³ç­–è€…ï¼‰
        research_manager_node = DecisionMakerNode(
            self.llm_setup.deep_thinking_llm,
            self.memory_manager.memories["invest_judge_memory"],
            "research_manager"
        ).create_decision_node()

        workflow.add_node("Bull Researcher", bull_node)
        workflow.add_node("Bear Researcher", bear_node)
        workflow.add_node("Research Manager", research_manager_node)

    def _configure_edges(self, workflow, selected_analysts):
        """é…ç½®è¾¹å’Œæ¡ä»¶é€»è¾‘"""
        conditional_logic = ConditionalDecisionNode({
            "max_debate_rounds": 2,
            "max_risk_rounds": 3
        })

        # è®¾ç½®èµ·ç‚¹
        first_analyst = selected_analysts[0]
        workflow.add_edge(START, f"{first_analyst.capitalize()} Analyst")

        # é…ç½®åˆ†æå¸ˆé“¾
        for i, analyst_type in enumerate(selected_analysts):
            current_analyst = f"{analyst_type.capitalize()} Analyst"
            current_tools = f"tools_{analyst_type}"
            current_clear = f"Msg Clear {analyst_type.capitalize()}"

            # æ¡ä»¶è¾¹ï¼šå†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·
            workflow.add_conditional_edges(
                current_analyst,
                conditional_logic.create_decision_router("tool_continuation"),
                [current_tools, current_clear]
            )

            # å·¥å…·å›åˆ°åˆ†æå¸ˆ
            workflow.add_edge(current_tools, current_analyst)

            # è¿æ¥åˆ°ä¸‹ä¸€ä¸ªåˆ†æå¸ˆæˆ–è¾é˜¶æ®µ
            if i < len(selected_analysts) - 1:
                next_analyst = f"{selected_analysts[i+1].capitalize()} Analyst"
                workflow.add_edge(current_clear, next_analyst)
            else:
                workflow.add_edge(current_clear, "Bull Researcher")

        # é…ç½®è¾é€»è¾‘
        workflow.add_conditional_edges(
            "Bull Researcher",
            conditional_logic.create_decision_router("debate_progression"),
            {
                "Bear Researcher": "Bear Researcher",
                "Research Manager": "Research Manager"
            }
        )

        workflow.add_conditional_edges(
            "Bear Researcher",
            conditional_logic.create_decision_router("debate_progression"),
            {
                "Bull Researcher": "Bull Researcher",
                "Research Manager": "Research Manager"
            }
        )

        # è¿æ¥åˆ°äº¤æ˜“å‘˜å’Œé£é™©ç®¡ç†
        workflow.add_edge("Research Manager", "Trader")
        workflow.add_edge("Trader", "Risky Analyst")

        # é…ç½®é£é™©åˆ†æå¾ªç¯
        # ... (ç±»ä¼¼çš„é£é™©åˆ†æé…ç½®)

        workflow.add_edge("Risk Judge", END)
```

### å·¥ä½œæµæ‰§è¡Œç¤ºä¾‹

```python
# ä½¿ç”¨ç¤ºä¾‹
async def run_trading_decision_workflow():
    """è¿è¡Œå®Œæ•´çš„äº¤æ˜“å†³ç­–å·¥ä½œæµ"""

    # 1. é…ç½®
    config = {
        "llm_provider": "openai",
        "deep_think_llm": "gpt-4",
        "quick_think_llm": "gpt-3.5-turbo",
        "memory_enabled": True,
        "max_debate_rounds": 2,
        "max_risk_rounds": 3
    }

    # 2. åˆ›å»ºå·¥ä½œæµ
    builder = TradingAgentsWorkflowBuilder(config)
    workflow = builder.create_workflow(
        selected_analysts=["market", "fundamentals", "news", "social"]
    )

    # 3. è®¾ç½®è¾“å…¥
    initial_state = {
        "company_of_interest": "AAPL",
        "trade_date": "2024-01-15",
        "messages": []
    }

    # 4. æ‰§è¡Œå·¥ä½œæµ
    print("ğŸš€ å¼€å§‹äº¤æ˜“å†³ç­–å·¥ä½œæµ...")

    final_state = workflow.invoke(initial_state)

    # 5. è¾“å‡ºç»“æœ
    print("ğŸ“Š å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")
    print(f"ç›®æ ‡è‚¡ç¥¨: {final_state['company_of_interest']}")
    print(f"åˆ†ææ—¥æœŸ: {final_state['trade_date']}")
    print(f"æœ€ç»ˆå†³ç­–: {final_state['final_trade_decision']}")

    # 6. è´¨é‡è¯„ä¼°
    quality_passed, quality_message = builder.quality_gate.validate_analysis_quality(final_state)
    print(f"è´¨é‡è¯„ä¼°: {'âœ… é€šè¿‡' if quality_passed else 'âŒ å¤±è´¥'} - {quality_message}")

    return final_state

# è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    import asyncio
    result = asyncio.run(run_trading_decision_workflow())
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–ä¸ç›‘æ§

### Tokenä½¿ç”¨ä¼˜åŒ–ç­–ç•¥

```python
class TokenOptimizationManager:
    """Tokenä½¿ç”¨ä¼˜åŒ–ç®¡ç†å™¨"""

    def __init__(self, max_context_size=4000):
        self.max_context_size = max_context_size
        self.token_usage_tracker = {}

    def optimize_context_for_node(self, state: TradingWorkflowState,
                                 node_type: str) -> str:
        """ä¸ºç‰¹å®šèŠ‚ç‚¹ä¼˜åŒ–ä¸Šä¸‹æ–‡"""

        # èŠ‚ç‚¹ç‰¹å®šçš„ä¸Šä¸‹æ–‡éœ€æ±‚
        context_needs = {
            "market_analyst": ["company_of_interest", "trade_date"],
            "bull_researcher": ["market_report", "fundamentals_report", "investment_debate_state"],
            "risk_manager": ["trader_investment_plan", "risk_debate_state"]
        }

        # åªæå–å¿…è¦å­—æ®µ
        essential_context = {}
        for field in context_needs.get(node_type, []):
            if field in state and state[field]:
                essential_context[field] = self._compress_if_needed(state[field])

        return self._format_context(essential_context)

    def _compress_if_needed(self, content: str) -> str:
        """å‹ç¼©å†…å®¹ä»¥èŠ‚çœToken"""
        if len(content) > 1000:
            # æå–å…³é”®ä¿¡æ¯
            lines = content.split('\n')
            key_lines = [line for line in lines[:10] if len(line.strip()) > 0]
            return '\n'.join(key_lines[:5]) + "\n... [å†…å®¹æˆªæ–­]"
        return content

    def track_token_usage(self, node_name: str, input_tokens: int,
                         output_tokens: int):
        """è·Ÿè¸ªTokenä½¿ç”¨æƒ…å†µ"""
        if node_name not in self.token_usage_tracker:
            self.token_usage_tracker[node_name] = {
                "total_input": 0,
                "total_output": 0,
                "call_count": 0
            }

        self.token_usage_tracker[node_name]["total_input"] += input_tokens
        self.token_usage_tracker[node_name]["total_output"] += output_tokens
        self.token_usage_tracker[node_name]["call_count"] += 1

    def get_usage_report(self) -> dict:
        """è·å–Tokenä½¿ç”¨æŠ¥å‘Š"""
        total_input = sum(node["total_input"] for node in self.token_usage_tracker.values())
        total_output = sum(node["total_output"] for node in self.token_usage_tracker.values())

        return {
            "total_tokens": total_input + total_output,
            "total_input_tokens": total_input,
            "total_output_tokens": total_output,
            "by_node": self.token_usage_tracker
        }
```

### å®æ—¶ç›‘æ§é¢æ¿

```python
class WorkflowMonitor:
    """å·¥ä½œæµç›‘æ§å™¨"""

    def __init__(self):
        self.execution_metrics = {}
        self.error_tracker = {}
        self.performance_logs = []

    def log_node_execution(self, node_name: str, execution_time: float,
                          status: str, token_usage: dict = None):
        """è®°å½•èŠ‚ç‚¹æ‰§è¡Œä¿¡æ¯"""
        timestamp = datetime.now()

        log_entry = {
            "timestamp": timestamp,
            "node_name": node_name,
            "execution_time": execution_time,
            "status": status,
            "token_usage": token_usage or {}
        }

        self.performance_logs.append(log_entry)

        if node_name not in self.execution_metrics:
            self.execution_metrics[node_name] = {
                "total_executions": 0,
                "total_time": 0,
                "success_count": 0,
                "error_count": 0
            }

        metrics = self.execution_metrics[node_name]
        metrics["total_executions"] += 1
        metrics["total_time"] += execution_time

        if status == "success":
            metrics["success_count"] += 1
        else:
            metrics["error_count"] += 1

    def generate_performance_report(self) -> dict:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        report = {
            "workflow_metrics": {},
            "node_performance": {},
            "error_summary": self.error_tracker,
            "recommendations": []
        }

        # è®¡ç®—æ•´ä½“æŒ‡æ ‡
        total_time = sum(log["execution_time"] for log in self.performance_logs)
        total_executions = len(self.performance_logs)

        report["workflow_metrics"] = {
            "total_execution_time": total_time,
            "average_execution_time": total_time / total_executions if total_executions > 0 else 0,
            "total_nodes_executed": total_executions,
            "overall_success_rate": sum(1 for log in self.performance_logs if log["status"] == "success") / total_executions if total_executions > 0 else 0
        }

        # èŠ‚ç‚¹æ€§èƒ½åˆ†æ
        for node_name, metrics in self.execution_metrics.items():
            avg_time = metrics["total_time"] / metrics["total_executions"]
            success_rate = metrics["success_count"] / metrics["total_executions"]

            report["node_performance"][node_name] = {
                "average_execution_time": avg_time,
                "success_rate": success_rate,
                "total_executions": metrics["total_executions"]
            }

            # æ€§èƒ½å»ºè®®
            if avg_time > 30:  # è¶…è¿‡30ç§’
                report["recommendations"].append(f"èŠ‚ç‚¹ {node_name} æ‰§è¡Œæ—¶é—´è¿‡é•¿ï¼Œå»ºè®®ä¼˜åŒ–")
            if success_rate < 0.9:  # æˆåŠŸç‡ä½äº90%
                report["recommendations"].append(f"èŠ‚ç‚¹ {node_name} æˆåŠŸç‡åä½ï¼Œéœ€è¦è°ƒè¯•")

        return report
```

---

## ğŸ¯ ä¸AIç¼–ç¨‹æ•™ç»ƒæŒ‡å—v2çš„å¯¹ç…§åˆ†æ

### å·¥ä½œæµç¼–æ’æ¨¡å¼å¯¹æ¯”

| AIç¼–ç¨‹æ•™ç»ƒæŒ‡å—v2æ¦‚å¿µ | TradingAgentså®ç° | å®é™…åº”ç”¨æ•ˆæœ |
|-------------------|------------------|-------------|
| **èŠ‚ç‚¹ï¼ˆNodeï¼‰** | 15ä¸ªä¸“ä¸šåŒ–AgentèŠ‚ç‚¹ | æ¸…æ™°çš„åŠŸèƒ½åˆ’åˆ†ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±• |
| **è¾¹ï¼ˆEdgeï¼‰** | æ¡ä»¶åˆ†æ”¯ + ä¸²è¡Œè¿æ¥ | æ™ºèƒ½è·¯ç”±ï¼Œæ ¹æ®çŠ¶æ€åŠ¨æ€é€‰æ‹©è·¯å¾„ |
| **çŠ¶æ€ï¼ˆStateï¼‰** | å¤šå±‚æ¬¡åµŒå¥—çŠ¶æ€æ¨¡å‹ | å®Œæ•´çš„ä¸Šä¸‹æ–‡ä¼ é€’ï¼Œä¿¡æ¯æ— æŸä¼ é€’ |
| **æ¡ä»¶è¾¹ï¼ˆConditional Edgeï¼‰** | 4ç§å†³ç­–è·¯ç”±å™¨ | é€‚åº”ä¸åŒåœºæ™¯çš„æ™ºèƒ½å†³ç­– |
| **æ£€æŸ¥ç‚¹ï¼ˆCheckpointï¼‰** | è´¨é‡é—¨ç¦ + è®°å¿†ç³»ç»Ÿ | è‡ªåŠ¨è´¨é‡æ§åˆ¶å’ŒæŒç»­å­¦ä¹  |

### å·¥ä½œæµå¤æ‚åº¦åˆ†çº§

```mermaid
graph LR
    subgraph "ç®€å•çº§åˆ«ï¼ˆæŒ‡å—v2ç¤ºä¾‹ï¼‰"
        A1[éœ€æ±‚åˆ†æ] --> A2[ä»£ç ç”Ÿæˆ] --> A3[æµ‹è¯•éªŒè¯]
    end

    subgraph "ä¸­ç­‰çº§åˆ«ï¼ˆTradingAgentsæ ¸å¿ƒï¼‰"
        B1[å¹¶è¡Œæ•°æ®é‡‡é›†] --> B2[åºåˆ—åŒ–è¾©è®º] --> B3[å†³ç­–ç”Ÿæˆ]
    end

    subgraph "å¤æ‚çº§åˆ«ï¼ˆTradingAgentså®Œæ•´ï¼‰"
        C1[å¤šæºå¹¶è¡Œåˆ†æ] --> C2[å¤šè½®è¾©è®ºå¾ªç¯] --> C3[å¤šè§’åº¦é£é™©è¯„ä¼°] --> C4[æœ€ç»ˆç»¼åˆå†³ç­–]
    end
```

### åº”ç”¨åœºæ™¯é€‚é…æŒ‡å—

#### 1. ç®€å•å†³ç­–åœºæ™¯ï¼ˆç±»ä¼¼æŒ‡å—v2çš„åŸºç¡€ç¤ºä¾‹ï¼‰
```python
# é€‚ç”¨äºï¼šå•ä¸€æ•°æ®æºï¼Œç®€å•åˆ†æ
simple_workflow = create_simple_trading_workflow([
    "market_analysis_node",
    "simple_decision_node"
])
```

#### 2. ä¸­ç­‰å¤æ‚åœºæ™¯ï¼ˆTradingAgentsçš„ç®€åŒ–ç‰ˆï¼‰
```python
# é€‚ç”¨äºï¼šå¤šæ•°æ®æºï¼ŒåŸºç¡€è¾©è®º
medium_workflow = create_medium_trading_workflow([
    "parallel_analysis_nodes",
    "bull_bear_debate",
    "final_decision"
])
```

#### 3. å¤æ‚å†³ç­–åœºæ™¯ï¼ˆTradingAgentså®Œæ•´ç‰ˆï¼‰
```python
# é€‚ç”¨äºï¼šå…¨æ–¹ä½åˆ†æï¼Œå¤šè½®è¾©è®ºï¼Œé£é™©ç®¡ç†
complex_workflow = create_full_trading_workflow([
    "multi_source_analysis",
    "investment_debate_cycle",
    "risk_management_cycle",
    "comprehensive_decision"
])
```

---

## ğŸš€ å¯å¤ç”¨å·¥ä½œæµæ¨¡æ¿

### 1. å¤šAgentå¹¶è¡Œåˆ†ææ¨¡æ¿

```python
def create_parallel_analysis_template(analyst_types: List[str],
                                     data_sources: Dict[str, List[str]]):
    """
    åˆ›å»ºå¹¶è¡Œåˆ†æå·¥ä½œæµæ¨¡æ¿

    é€‚ç”¨åœºæ™¯ï¼š
    - éœ€è¦åŒæ—¶å¤„ç†å¤šç§æ•°æ®æº
    - å„åˆ†æå¸ˆç‹¬ç«‹å·¥ä½œ
    - ç»“æœæ±‡æ€»åˆ°ä¸‹ä¸€é˜¶æ®µ
    """
    workflow = StateGraph(AgentState)

    # æ·»åŠ å¹¶è¡Œåˆ†æèŠ‚ç‚¹
    for analyst_type in analyst_types:
        analyst_node = create_analyst_node(analyst_type, data_sources[analyst_type])
        tool_node = create_tool_node(data_sources[analyst_type])
        clear_node = create_msg_delete()

        workflow.add_node(f"{analyst_type}_analyst", analyst_node)
        workflow.add_node(f"{analyst_type}_tools", tool_node)
        workflow.add_node(f"{analyst_type}_clear", clear_node)

        # é…ç½®æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            f"{analyst_type}_analyst",
            create_tool_decision_router(analyst_type),
            {
                f"{analyst_type}_tools": f"{analyst_type}_tools",
                f"{analyst_type}_clear": f"{analyst_type}_clear"
            }
        )
        workflow.add_edge(f"{analyst_type}_tools", f"{analyst_type}_analyst")

    # æ±‡èšç‚¹
    convergence_node = create_convergence_node(analyst_types)
    workflow.add_node("convergence", convergence_node)

    # è¿æ¥æ‰€æœ‰clearèŠ‚ç‚¹åˆ°æ±‡èšç‚¹
    for analyst_type in analyst_types:
        workflow.add_edge(f"{analyst_type}_clear", "convergence")

    return workflow.compile()
```

### 2. è¾©è®ºå¼å†³ç­–æ¨¡æ¿

```python
def create_debate_decision_template(debate_participants: List[str],
                                   max_rounds: int = 3):
    """
    åˆ›å»ºè¾©è®ºå¼å†³ç­–å·¥ä½œæµæ¨¡æ¿

    é€‚ç”¨åœºæ™¯ï¼š
    - éœ€è¦å¤šè§’åº¦è§‚ç‚¹å†²çª
    - é€šè¿‡è¾©è®ºæé«˜å†³ç­–è´¨é‡
    - æœ‰æ˜ç¡®çš„è½®æ¬¡é™åˆ¶
    """
    workflow = StateGraph(AgentState)

    # æ·»åŠ è¾©è®ºå‚ä¸è€…èŠ‚ç‚¹
    for participant in debate_participants:
        participant_node = create_debate_participant_node(participant)
        workflow.add_node(participant, participant_node)

    # æ·»åŠ è£åˆ¤èŠ‚ç‚¹
    judge_node = create_judge_node(debate_participants)
    workflow.add_node("judge", judge_node)

    # è®¾ç½®è¾©è®ºå¾ªç¯
    def debate_router(state):
        if state["debate_count"] >= max_rounds * len(debate_participants):
            return "judge"

        # è½®æ¢å‘è¨€è€…
        current_round = state["debate_count"] % len(debate_participants)
        return debate_participants[current_round]

    # é…ç½®è¾©è®ºæµç¨‹
    for participant in debate_participants:
        workflow.add_conditional_edges(
            participant,
            debate_router,
            {**{p: p for p in debate_participants}, "judge": "judge"}
        )

    return workflow.compile()
```

### 3. è´¨é‡é—¨ç¦æ¨¡æ¿

```python
def create_quality_gate_template(quality_checks: List[str],
                                retry_limit: int = 3):
    """
    åˆ›å»ºè´¨é‡é—¨ç¦å·¥ä½œæµæ¨¡æ¿

    é€‚ç”¨åœºæ™¯ï¼š
    - éœ€è¦ä¸¥æ ¼çš„è´¨é‡æ§åˆ¶
    - æ”¯æŒè‡ªåŠ¨é‡è¯•æœºåˆ¶
    - å¯é…ç½®çš„æ£€æŸ¥é¡¹ç›®
    """
    workflow = StateGraph(AgentState)

    # ä¸»å¤„ç†èŠ‚ç‚¹
    main_processor = create_main_processor_node()
    workflow.add_node("main_processor", main_processor)

    # è´¨é‡æ£€æŸ¥èŠ‚ç‚¹
    for check_type in quality_checks:
        check_node = create_quality_check_node(check_type)
        workflow.add_node(f"check_{check_type}", check_node)

    # é‡è¯•å¤„ç†èŠ‚ç‚¹
    retry_node = create_retry_node()
    workflow.add_node("retry", retry_node)

    # æœ€ç»ˆéªŒè¯èŠ‚ç‚¹
    final_validation = create_final_validation_node()
    workflow.add_node("final_validation", final_validation)

    # é…ç½®è´¨é‡é—¨ç¦é€»è¾‘
    def quality_gate_router(state):
        # æ£€æŸ¥æ‰€æœ‰è´¨é‡æŒ‡æ ‡
        for check_type in quality_checks:
            if not state.get(f"{check_type}_passed", False):
                if state.get("retry_count", 0) < retry_limit:
                    return "retry"
                else:
                    return f"check_{check_type}"
        return "final_validation"

    workflow.add_conditional_edges(
        "main_processor",
        quality_gate_router,
        {
            **{f"check_{check}": f"check_{check}" for check in quality_checks},
            "retry": "retry",
            "final_validation": "final_validation"
        }
    )

    return workflow.compile()
```

---

## ğŸ“š å­¦ä¹ å»ºè®®ä¸æœ€ä½³å®è·µ

### å­¦ä¹ è·¯å¾„è§„åˆ’

```mermaid
graph TB
    subgraph "ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€ç†è§£"
        A1[ç†è§£LangGraphåŸºç¡€æ¦‚å¿µ]
        A2[æŒæ¡çŠ¶æ€ç®¡ç†æ¨¡å¼]
        A3[å­¦ä¹ èŠ‚ç‚¹è®¾è®¡æ¨¡å¼]
        A1 --> A2 --> A3
    end

    subgraph "ç¬¬äºŒé˜¶æ®µï¼šå®è·µåº”ç”¨"
        B1[å®ç°ç®€å•çš„3èŠ‚ç‚¹å·¥ä½œæµ]
        B2[æ·»åŠ æ¡ä»¶åˆ†æ”¯é€»è¾‘]
        B3[é›†æˆè®°å¿†å’Œåæ€æœºåˆ¶]
        B1 --> B2 --> B3
    end

    subgraph "ç¬¬ä¸‰é˜¶æ®µï¼šé«˜çº§ç‰¹æ€§"
        C1[è®¾è®¡å¤æ‚çš„å¤šAgentåä½œ]
        C2[å®ç°åŠ¨æ€è·¯ç”±å’Œå¾ªç¯]
        C3[ä¼˜åŒ–æ€§èƒ½å’ŒTokenä½¿ç”¨]
        C1 --> C2 --> C3
    end

    subgraph "ç¬¬å››é˜¶æ®µï¼šç”Ÿäº§å°±ç»ª"
        D1[å»ºç«‹ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ]
        D2[å®ç°é”™è¯¯å¤„ç†å’Œæ¢å¤]
        D3[æ„å»ºå¯å¤ç”¨æ¨¡æ¿åº“]
        D1 --> D2 --> D3
    end

    A3 --> B1
    B3 --> C1
    C3 --> D1
```

### å¼€å‘æœ€ä½³å®è·µ

#### 1. èŠ‚ç‚¹è®¾è®¡åŸåˆ™
```python
# âœ… å¥½çš„èŠ‚ç‚¹è®¾è®¡
def create_focused_analyst_node(llm, data_source, analysis_focus):
    """
    ä¸“æ³¨å•ä¸€èŒè´£çš„åˆ†æå¸ˆèŠ‚ç‚¹
    - æ˜ç¡®çš„è¾“å…¥è¾“å‡º
    - å•ä¸€æ•°æ®æº
    - ç‰¹å®šåˆ†æç›®æ ‡
    """
    def analyst_node(state):
        # 1. è¾“å…¥éªŒè¯
        if not validate_input(state):
            return create_error_state("è¾“å…¥éªŒè¯å¤±è´¥")

        # 2. æ ¸å¿ƒå¤„ç†é€»è¾‘
        result = perform_analysis(state, data_source, analysis_focus)

        # 3. è¾“å‡ºæ ¼å¼åŒ–
        return format_output(state, result)

    return analyst_node

# âŒ é¿å…çš„èŠ‚ç‚¹è®¾è®¡
def create_everything_node(llm, all_tools, all_tasks):
    """
    é¿å…ï¼šæ‰¿æ‹…è¿‡å¤šèŒè´£çš„ä¸‡èƒ½èŠ‚ç‚¹
    - éš¾ä»¥è°ƒè¯•
    - éš¾ä»¥å¤ç”¨
    - éš¾ä»¥ä¼˜åŒ–
    """
    pass
```

#### 2. çŠ¶æ€ç®¡ç†ç­–ç•¥
```python
# âœ… è‰¯å¥½çš„çŠ¶æ€ç®¡ç†
class StateManager:
    def __init__(self):
        self.state_validators = {}
        self.state_transformers = {}

    def validate_state_transition(self, from_node: str, to_node: str, state: dict) -> bool:
        """éªŒè¯çŠ¶æ€è½¬æ¢çš„åˆæ³•æ€§"""
        required_fields = self.get_required_fields(to_node)
        return all(field in state and state[field] for field in required_fields)

    def transform_state(self, state: dict, transformation: str) -> dict:
        """å®‰å…¨çš„çŠ¶æ€è½¬æ¢"""
        if transformation in self.state_transformers:
            return self.state_transformers[transformation](state)
        return state

    def create_state_snapshot(self, state: dict) -> str:
        """åˆ›å»ºçŠ¶æ€å¿«ç…§ç”¨äºè°ƒè¯•"""
        return json.dumps({
            k: str(v)[:100] + "..." if len(str(v)) > 100 else v
            for k, v in state.items()
        }, indent=2)
```

#### 3. é”™è¯¯å¤„ç†å’Œæ¢å¤
```python
class RobustWorkflowExecutor:
    """å¥å£®çš„å·¥ä½œæµæ‰§è¡Œå™¨"""

    def __init__(self, workflow, max_retries=3):
        self.workflow = workflow
        self.max_retries = max_retries
        self.error_handlers = {}

    def execute_with_recovery(self, initial_state: dict) -> dict:
        """å¸¦æ¢å¤æœºåˆ¶çš„æ‰§è¡Œ"""
        retry_count = 0
        last_error = None

        while retry_count < self.max_retries:
            try:
                return self.workflow.invoke(initial_state)

            except Exception as e:
                retry_count += 1
                last_error = e

                # å°è¯•æ¢å¤
                recovery_state = self.attempt_recovery(initial_state, e)
                if recovery_state:
                    initial_state = recovery_state
                    continue

                # è®°å½•é”™è¯¯
                self.log_error(e, retry_count, initial_state)

                if retry_count >= self.max_retries:
                    break

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        return self.create_failure_state(last_error, initial_state)

    def attempt_recovery(self, state: dict, error: Exception) -> dict:
        """å°è¯•ä»é”™è¯¯ä¸­æ¢å¤"""
        error_type = type(error).__name__

        if error_type in self.error_handlers:
            return self.error_handlers[error_type](state, error)

        # é€šç”¨æ¢å¤ç­–ç•¥
        if "token" in str(error).lower():
            # Tokené™åˆ¶é”™è¯¯ï¼šç®€åŒ–çŠ¶æ€
            return self.simplify_state(state)

        if "timeout" in str(error).lower():
            # è¶…æ—¶é”™è¯¯ï¼šé‡ç½®æŸäº›å­—æ®µ
            return self.reset_timeout_fields(state)

        return None
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 1. Tokenä¼˜åŒ–ç­–ç•¥
- **ä¸Šä¸‹æ–‡å‹ç¼©**ï¼šåªä¼ é€’å¿…è¦ä¿¡æ¯ç»™æ¯ä¸ªèŠ‚ç‚¹
- **å¢é‡æ›´æ–°**ï¼šé¿å…é‡å¤ä¼ é€’å¤§é‡ä¸å˜æ•°æ®
- **æ™ºèƒ½æ‘˜è¦**ï¼šå¯¹é•¿æ–‡æœ¬è¿›è¡Œæ™ºèƒ½æ‘˜è¦
- **ç¼“å­˜æœºåˆ¶**ï¼šç¼“å­˜é‡å¤çš„åˆ†æç»“æœ

#### 2. å¹¶å‘æ‰§è¡Œä¼˜åŒ–
- **å¹¶è¡Œæ•°æ®è·å–**ï¼šåŒæ—¶è°ƒç”¨å¤šä¸ªæ•°æ®æºAPI
- **å¼‚æ­¥èŠ‚ç‚¹æ‰§è¡Œ**ï¼šå¯¹ç‹¬ç«‹èŠ‚ç‚¹ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œ
- **è´Ÿè½½å‡è¡¡**ï¼šåœ¨å¤šä¸ªLLMå®ä¾‹é—´åˆ†é…ä»»åŠ¡
- **èµ„æºæ± ç®¡ç†**ï¼šåˆç†ç®¡ç†APIè°ƒç”¨é™åˆ¶

#### 3. å†…å­˜å’Œå­˜å‚¨ä¼˜åŒ–
- **çŠ¶æ€è£å‰ª**ï¼šå®šæœŸæ¸…ç†ä¸éœ€è¦çš„å†å²çŠ¶æ€
- **åˆ†æ®µå­˜å‚¨**ï¼šå°†å¤§çŠ¶æ€åˆ†æ®µå­˜å‚¨
- **å‹ç¼©å­˜å‚¨**ï¼šå¯¹å­˜å‚¨çš„çŠ¶æ€è¿›è¡Œå‹ç¼©
- **ç´¢å¼•ä¼˜åŒ–**ï¼šä¸ºé¢‘ç¹æŸ¥è¯¢çš„å­—æ®µå»ºç«‹ç´¢å¼•

---

## ğŸ“ æ€»ç»“ä¸å±•æœ›

### TradingAgentsçš„å·¥ä½œæµç¼–æ’åˆ›æ–°

TradingAgentsé¡¹ç›®æˆåŠŸåœ°å°†AIç¼–ç¨‹æ•™ç»ƒæŒ‡å—v2ä¸­çš„å·¥ä½œæµç¼–æ’ç†å¿µåº”ç”¨åˆ°å¤æ‚çš„äº¤æ˜“å†³ç­–ç³»ç»Ÿä¸­ï¼Œå®ç°äº†ä»¥ä¸‹åˆ›æ–°ï¼š

1. **å¤šå±‚æ¬¡çŠ¶æ€ç®¡ç†**ï¼šä»ç®€å•çš„çº¿æ€§çŠ¶æ€åˆ°å¤æ‚çš„åµŒå¥—çŠ¶æ€æ¨¡å‹
2. **æ™ºèƒ½å†³ç­–è·¯ç”±**ï¼šåŸºäºå†…å®¹å’Œä¸Šä¸‹æ–‡çš„åŠ¨æ€è·¯ç”±æœºåˆ¶
3. **å¾ªç¯è¾©è®ºæœºåˆ¶**ï¼šé€šè¿‡å¤šè½®å¯¹è¯æé«˜å†³ç­–è´¨é‡
4. **è®°å¿†ä¸å­¦ä¹ **ï¼šé›†æˆå†å²ç»éªŒå’Œåæ€æœºåˆ¶
5. **è´¨é‡é—¨ç¦ç³»ç»Ÿ**ï¼šè‡ªåŠ¨åŒ–çš„è´¨é‡æ§åˆ¶å’ŒéªŒè¯

### å…³é”®ç»éªŒæ€»ç»“

| è®¾è®¡åŸåˆ™ | TradingAgentså®è·µ | å¯å¤ç”¨æ¨¡å¼ |
|----------|------------------|-----------|
| **æ¨¡å—åŒ–è®¾è®¡** | 15ä¸ªç‹¬ç«‹AgentèŠ‚ç‚¹ | æŒ‰åŠŸèƒ½èŒè´£åˆ†è§£èŠ‚ç‚¹ |
| **çŠ¶æ€ä¸€è‡´æ€§** | ç»Ÿä¸€çš„çŠ¶æ€æ¨¡å‹ | TypedDict + éªŒè¯æœºåˆ¶ |
| **é”™è¯¯æ¢å¤** | å¤šå±‚æ¬¡é‡è¯•æœºåˆ¶ | æ¸è¿›å¼é™çº§ç­–ç•¥ |
| **æ€§èƒ½ä¼˜åŒ–** | Tokenæ™ºèƒ½ç®¡ç† | ä¸Šä¸‹æ–‡å‹ç¼© + ç¼“å­˜ |
| **å¯è§‚æµ‹æ€§** | å®Œæ•´çš„æ—¥å¿—ç›‘æ§ | ç»“æ„åŒ–æ—¥å¿— + æŒ‡æ ‡æ”¶é›† |

### é€‚ç”¨åœºæ™¯æ‰©å±•

åŸºäºTradingAgentsçš„è®¾è®¡æ¨¡å¼ï¼Œå¯ä»¥æ‰©å±•åˆ°ä»¥ä¸‹é¢†åŸŸï¼š

#### 1. åŒ»ç–—è¯Šæ–­ç³»ç»Ÿ
```mermaid
graph TB
    ç—‡çŠ¶åˆ†æå¸ˆ --> å½±åƒåˆ†æå¸ˆ
    å½±åƒåˆ†æå¸ˆ --> å®éªŒå®¤åˆ†æå¸ˆ
    å®éªŒå®¤åˆ†æå¸ˆ --> ä¸“ç§‘åŒ»ç”ŸA
    ä¸“ç§‘åŒ»ç”ŸA --> ä¸“ç§‘åŒ»ç”ŸB
    ä¸“ç§‘åŒ»ç”ŸB --> ä¸»æ²»åŒ»ç”Ÿ
    ä¸»æ²»åŒ»ç”Ÿ --> æœ€ç»ˆè¯Šæ–­
```

#### 2. æ³•å¾‹å’¨è¯¢ç³»ç»Ÿ
```mermaid
graph TB
    æ¡ˆä¾‹åˆ†æå¸ˆ --> æ³•æ¡åˆ†æå¸ˆ
    æ³•æ¡åˆ†æå¸ˆ --> åˆ¤ä¾‹åˆ†æå¸ˆ
    åˆ¤ä¾‹åˆ†æå¸ˆ --> å¾‹å¸ˆA
    å¾‹å¸ˆA --> å¾‹å¸ˆB
    å¾‹å¸ˆB --> ä¸»ä»»å¾‹å¸ˆ
    ä¸»ä»»å¾‹å¸ˆ --> æ³•å¾‹å»ºè®®
```

#### 3. äº§å“è®¾è®¡ç³»ç»Ÿ
```mermaid
graph TB
    ç”¨æˆ·ç ”ç©¶å¸ˆ --> å¸‚åœºåˆ†æå¸ˆ
    å¸‚åœºåˆ†æå¸ˆ --> æŠ€æœ¯åˆ†æå¸ˆ
    æŠ€æœ¯åˆ†æå¸ˆ --> è®¾è®¡å¸ˆA
    è®¾è®¡å¸ˆA --> è®¾è®¡å¸ˆB
    è®¾è®¡å¸ˆB --> äº§å“ç»ç†
    äº§å“ç»ç† --> äº§å“æ–¹æ¡ˆ
```

### æœªæ¥å‘å±•æ–¹å‘

1. **è‡ªé€‚åº”å·¥ä½œæµ**ï¼šæ ¹æ®é—®é¢˜å¤æ‚åº¦è‡ªåŠ¨è°ƒæ•´å·¥ä½œæµç»“æ„
2. **è”é‚¦å­¦ä¹ é›†æˆ**ï¼šå¤šä¸ªå·¥ä½œæµå®ä¾‹é—´çš„çŸ¥è¯†å…±äº«
3. **å®æ—¶ä¼˜åŒ–**ï¼šåŸºäºæ‰§è¡Œåé¦ˆçš„å®æ—¶å·¥ä½œæµä¼˜åŒ–
4. **å¤šæ¨¡æ€æ‰©å±•**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®
5. **è¾¹ç¼˜è®¡ç®—éƒ¨ç½²**ï¼šè½»é‡åŒ–ç‰ˆæœ¬ç”¨äºè¾¹ç¼˜è®¾å¤‡

### è‡´å¼€å‘è€…çš„å»ºè®®

1. **ä»ç®€å•å¼€å§‹**ï¼šå…ˆå®ç°åŸºç¡€çš„3-5èŠ‚ç‚¹å·¥ä½œæµ
2. **é€æ­¥å¢åŠ å¤æ‚æ€§**ï¼šæ ¹æ®éœ€è¦æ·»åŠ è¾©è®ºã€å¾ªç¯ç­‰é«˜çº§ç‰¹æ€§
3. **é‡è§†çŠ¶æ€è®¾è®¡**ï¼šæŠ•å…¥æ—¶é—´è®¾è®¡å¥½çŠ¶æ€æ¨¡å‹ï¼Œè¿™æ˜¯æˆåŠŸçš„å…³é”®
4. **å»ºç«‹ç›‘æ§ä½“ç³»**ï¼šä»ç¬¬ä¸€å¤©å°±è€ƒè™‘å¯è§‚æµ‹æ€§å’Œè°ƒè¯•èƒ½åŠ›
5. **ç¤¾åŒºè´¡çŒ®**ï¼šå°†æˆåŠŸçš„æ¨¡å¼æŠ½è±¡ä¸ºå¯å¤ç”¨æ¨¡æ¿ï¼Œè´¡çŒ®ç»™ç¤¾åŒº

---

**æœ€åæ›´æ–°**: 2024-01-20
**ç‰ˆæœ¬**: v3.0
**ä½œè€…**: Claude AI Programming Coach
**åŸºäºé¡¹ç›®**: TradingAgents_CN_Web

**æ ¸å¿ƒè´¡çŒ®**:
- å®Œæ•´çš„LangGraphå·¥ä½œæµæ‹†è§£åˆ†æ
- å¯å¤ç”¨çš„å·¥ä½œæµè®¾è®¡æ¨¡å¼
- ä»ç†è®ºåˆ°å®è·µçš„å®Œæ•´æŒ‡å—
- é¢å‘æœªæ¥çš„æ‰©å±•å»ºè®®

æ„¿è¿™ä»½åˆ†æèƒ½å¸®åŠ©æ›´å¤šå¼€å‘è€…æŒæ¡å·¥ä½œæµç¼–æ’çš„ç²¾é«“ï¼Œæ„å»ºå‡ºæ›´åŠ æ™ºèƒ½å’Œå¯é çš„AIç³»ç»Ÿï¼ğŸš€